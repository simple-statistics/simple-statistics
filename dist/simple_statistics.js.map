{
  "version": 3,
  "sources": [
    "node_modules/browser-pack/_prelude.js",
    "index.js",
    "src/bayesian_classifier.js",
    "src/bernoulli_distribution.js",
    "src/binomial_distribution.js",
    "src/chi_squared_distribution_table.js",
    "src/chi_squared_goodness_of_fit.js",
    "src/chunk.js",
    "src/ckmeans.js",
    "src/cumulative_std_normal_probability.js",
    "src/epsilon.js",
    "src/equal_interval_breaks.js",
    "src/error_function.js",
    "src/factorial.js",
    "src/geometric_mean.js",
    "src/harmonic_mean.js",
    "src/interquartile_range.js",
    "src/inverse_error_function.js",
    "src/linear_regression.js",
    "src/linear_regression_line.js",
    "src/mad.js",
    "src/max.js",
    "src/mean.js",
    "src/median.js",
    "src/median_sorted.js",
    "src/min.js",
    "src/mixin.js",
    "src/mode.js",
    "src/mode_sorted.js",
    "src/numeric_sort.js",
    "src/perceptron.js",
    "src/poisson_distribution.js",
    "src/probit.js",
    "src/product.js",
    "src/quantile.js",
    "src/quantile_sorted.js",
    "src/r_squared.js",
    "src/root_mean_square.js",
    "src/sample.js",
    "src/sample_correlation.js",
    "src/sample_covariance.js",
    "src/sample_skewness.js",
    "src/sample_standard_deviation.js",
    "src/sample_variance.js",
    "src/shuffle.js",
    "src/shuffle_in_place.js",
    "src/sorted_unique_count.js",
    "src/standard_deviation.js",
    "src/standard_normal_table.js",
    "src/sum.js",
    "src/sum_nth_power_deviations.js",
    "src/t_test.js",
    "src/t_test_two_sample.js",
    "src/variance.js",
    "src/z_score.js"
  ],
  "names": [],
  "mappings": "AAAA;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5cA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA",
  "file": "generated.js",
  "sourceRoot": "",
  "sourcesContent": [
    "(function e(t,n,r){function s(o,u){if(!n[o]){if(!t[o]){var a=typeof require==\"function\"&&require;if(!u&&a)return a(o,!0);if(i)return i(o,!0);var f=new Error(\"Cannot find module '\"+o+\"'\");throw f.code=\"MODULE_NOT_FOUND\",f}var l=n[o]={exports:{}};t[o][0].call(l.exports,function(e){var n=t[o][1][e];return s(n?n:e)},l,l.exports,e,t,n,r)}return n[o].exports}var i=typeof require==\"function\"&&require;for(var o=0;o<r.length;o++)s(r[o]);return s})",
    "/* @flow */\n'use strict';\n\n// # simple-statistics\n//\n// A simple, literate statistics system.\n\nvar ss = module.exports = {};\n\n// Linear Regression\nss.linearRegression = require(18);\nss.linearRegressionLine = require(19);\nss.standardDeviation = require(47);\nss.rSquared = require(36);\nss.mode = require(27);\nss.modeSorted = require(28);\nss.min = require(25);\nss.max = require(21);\nss.sum = require(49);\nss.product = require(33);\nss.quantile = require(34);\nss.quantileSorted = require(35);\nss.iqr = ss.interquartileRange = require(16);\nss.medianAbsoluteDeviation = ss.mad = require(20);\nss.chunk = require(7);\nss.shuffle = require(44);\nss.shuffleInPlace = require(45);\nss.sample = require(38);\nss.ckmeans = require(8);\nss.sortedUniqueCount = require(46);\nss.sumNthPowerDeviations = require(50);\nss.equalIntervalBreaks = require(11);\n\n// sample statistics\nss.sampleCovariance = require(40);\nss.sampleCorrelation = require(39);\nss.sampleVariance = require(43);\nss.sampleStandardDeviation = require(42);\nss.sampleSkewness = require(41);\n\n// measures of centrality\nss.geometricMean = require(14);\nss.harmonicMean = require(15);\nss.mean = ss.average = require(22);\nss.median = require(23);\nss.medianSorted = require(24);\n\nss.rootMeanSquare = ss.rms = require(37);\nss.variance = require(53);\nss.tTest = require(51);\nss.tTestTwoSample = require(52);\n// ss.jenks = require('./src/jenks');\n\n// Classifiers\nss.bayesian = require(2);\nss.perceptron = require(30);\n\n// Distribution-related methods\nss.epsilon = require(10); // We make ε available to the test suite.\nss.factorial = require(13);\nss.bernoulliDistribution = require(3);\nss.binomialDistribution = require(4);\nss.poissonDistribution = require(31);\nss.chiSquaredGoodnessOfFit = require(6);\n\n// Normal distribution\nss.zScore = require(54);\nss.cumulativeStdNormalProbability = require(9);\nss.standardNormalTable = require(48);\nss.errorFunction = ss.erf = require(12);\nss.inverseErrorFunction = require(17);\nss.probit = require(32);\nss.mixin = require(26);\n",
    "'use strict';\n/* @flow */\n\n/**\n * [Bayesian Classifier](http://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n *\n * This is a naïve bayesian classifier that takes\n * singly-nested objects.\n *\n * @class\n * @example\n * var bayes = new BayesianClassifier();\n * bayes.train({\n *   species: 'Cat'\n * }, 'animal');\n * var result = bayes.score({\n *   species: 'Cat'\n * })\n * // result\n * // {\n * //   animal: 1\n * // }\n */\nfunction BayesianClassifier() {\n    // The number of items that are currently\n    // classified in the model\n    this.totalCount = 0;\n    // Every item classified in the model\n    this.data = {};\n}\n\n/**\n * Train the classifier with a new item, which has a single\n * dimension of Javascript literal keys and values.\n *\n * @param {Object} item an object with singly-deep properties\n * @param {string} category the category this item belongs to\n * @return {undefined} adds the item to the classifier\n */\nBayesianClassifier.prototype.train = function(item, category) {\n    // If the data object doesn't have any values\n    // for this category, create a new object for it.\n    if (!this.data[category]) {\n        this.data[category] = {};\n    }\n\n    // Iterate through each key in the item.\n    for (var k in item) {\n        var v = item[k];\n        // Initialize the nested object `data[category][k][item[k]]`\n        // with an object of keys that equal 0.\n        if (this.data[category][k] === undefined) {\n            this.data[category][k] = {};\n        }\n        if (this.data[category][k][v] === undefined) {\n            this.data[category][k][v] = 0;\n        }\n\n        // And increment the key for this key/value combination.\n        this.data[category][k][item[k]]++;\n    }\n\n    // Increment the number of items classified\n    this.totalCount++;\n};\n\n/**\n * Generate a score of how well this item matches all\n * possible categories based on its attributes\n *\n * @param {Object} item an item in the same format as with train\n * @returns {Object} of probabilities that this item belongs to a\n * given category.\n */\nBayesianClassifier.prototype.score = function(item) {\n    // Initialize an empty array of odds per category.\n    var odds = {}, category;\n    // Iterate through each key in the item,\n    // then iterate through each category that has been used\n    // in previous calls to `.train()`\n    for (var k in item) {\n        var v = item[k];\n        for (category in this.data) {\n            // Create an empty object for storing key - value combinations\n            // for this category.\n            if (odds[category] === undefined) { odds[category] = {}; }\n\n            // If this item doesn't even have a property, it counts for nothing,\n            // but if it does have the property that we're looking for from\n            // the item to categorize, it counts based on how popular it is\n            // versus the whole population.\n            if (this.data[category][k]) {\n                odds[category][k + '_' + v] = (this.data[category][k][v] || 0) / this.totalCount;\n            } else {\n                odds[category][k + '_' + v] = 0;\n            }\n        }\n    }\n\n    // Set up a new object that will contain sums of these odds by category\n    var oddsSums = {};\n\n    for (category in odds) {\n        // Tally all of the odds for each category-combination pair -\n        // the non-existence of a category does not add anything to the\n        // score.\n        for (var combination in odds[category]) {\n            if (oddsSums[category] === undefined) {\n                oddsSums[category] = 0;\n            }\n            oddsSums[category] += odds[category][combination];\n        }\n    }\n\n    return oddsSums;\n};\n\nmodule.exports = BayesianClassifier;\n",
    "'use strict';\n/* @flow */\n\nvar binomialDistribution = require(4);\n\n/**\n * The [Bernoulli distribution](http://en.wikipedia.org/wiki/Bernoulli_distribution)\n * is the probability discrete\n * distribution of a random variable which takes value 1 with success\n * probability `p` and value 0 with failure\n * probability `q` = 1 - `p`. It can be used, for example, to represent the\n * toss of a coin, where \"1\" is defined to mean \"heads\" and \"0\" is defined\n * to mean \"tails\" (or vice versa). It is\n * a special case of a Binomial Distribution\n * where `n` = 1.\n *\n * @param {number} p input value, between 0 and 1 inclusive\n * @returns {number} value of bernoulli distribution at this point\n */\nfunction bernoulliDistribution(p/*: number */) {\n    // Check that `p` is a valid probability (0 ≤ p ≤ 1)\n    if (p < 0 || p > 1 ) { return NaN; }\n\n    return binomialDistribution(1, p);\n}\n\nmodule.exports = bernoulliDistribution;\n",
    "'use strict';\n/* @flow */\n\nvar epsilon = require(10);\nvar factorial = require(13);\n\n/**\n * The [Binomial Distribution](http://en.wikipedia.org/wiki/Binomial_distribution) is the discrete probability\n * distribution of the number of successes in a sequence of n independent yes/no experiments, each of which yields\n * success with probability `probability`. Such a success/failure experiment is also called a Bernoulli experiment or\n * Bernoulli trial; when trials = 1, the Binomial Distribution is a Bernoulli Distribution.\n *\n * @param {number} trials number of trials to simulate\n * @param {number} probability\n * @returns {Object} output\n */\nfunction binomialDistribution(\n    trials/*: number */,\n    probability/*: number */)/*: ?Object */ {\n    // Check that `p` is a valid probability (0 ≤ p ≤ 1),\n    // that `n` is an integer, strictly positive.\n    if (probability < 0 || probability > 1 ||\n        trials <= 0 || trials % 1 !== 0) {\n        return undefined;\n    }\n\n    // We initialize `x`, the random variable, and `accumulator`, an accumulator\n    // for the cumulative distribution function to 0. `distribution_functions`\n    // is the object we'll return with the `probability_of_x` and the\n    // `cumulativeProbability_of_x`, as well as the calculated mean &\n    // variance. We iterate until the `cumulativeProbability_of_x` is\n    // within `epsilon` of 1.0.\n    var x = 0,\n        cumulativeProbability = 0,\n        cells = {};\n\n    // This algorithm iterates through each potential outcome,\n    // until the `cumulativeProbability` is very close to 1, at\n    // which point we've defined the vast majority of outcomes\n    do {\n        // a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function)\n        cells[x] = factorial(trials) /\n            (factorial(x) * factorial(trials - x)) *\n            (Math.pow(probability, x) * Math.pow(1 - probability, trials - x));\n        cumulativeProbability += cells[x];\n        x++;\n    // when the cumulativeProbability is nearly 1, we've calculated\n    // the useful range of this distribution\n    } while (cumulativeProbability < 1 - epsilon);\n\n    return cells;\n}\n\nmodule.exports = binomialDistribution;\n",
    "'use strict';\n/* @flow */\n\n/**\n * **Percentage Points of the χ2 (Chi-Squared) Distribution**\n *\n * The [χ2 (Chi-Squared) Distribution](http://en.wikipedia.org/wiki/Chi-squared_distribution) is used in the common\n * chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two\n * criteria of classification of qualitative data, and in confidence interval estimation for a population standard\n * deviation of a normal distribution from a sample standard deviation.\n *\n * Values from Appendix 1, Table III of William W. Hines & Douglas C. Montgomery, \"Probability and Statistics in\n * Engineering and Management Science\", Wiley (1980).\n */\nvar chiSquaredDistributionTable = { '1':\n   { '0.995': 0,\n     '0.99': 0,\n     '0.975': 0,\n     '0.95': 0,\n     '0.9': 0.02,\n     '0.5': 0.45,\n     '0.1': 2.71,\n     '0.05': 3.84,\n     '0.025': 5.02,\n     '0.01': 6.63,\n     '0.005': 7.88 },\n  '2':\n   { '0.995': 0.01,\n     '0.99': 0.02,\n     '0.975': 0.05,\n     '0.95': 0.1,\n     '0.9': 0.21,\n     '0.5': 1.39,\n     '0.1': 4.61,\n     '0.05': 5.99,\n     '0.025': 7.38,\n     '0.01': 9.21,\n     '0.005': 10.6 },\n  '3':\n   { '0.995': 0.07,\n     '0.99': 0.11,\n     '0.975': 0.22,\n     '0.95': 0.35,\n     '0.9': 0.58,\n     '0.5': 2.37,\n     '0.1': 6.25,\n     '0.05': 7.81,\n     '0.025': 9.35,\n     '0.01': 11.34,\n     '0.005': 12.84 },\n  '4':\n   { '0.995': 0.21,\n     '0.99': 0.3,\n     '0.975': 0.48,\n     '0.95': 0.71,\n     '0.9': 1.06,\n     '0.5': 3.36,\n     '0.1': 7.78,\n     '0.05': 9.49,\n     '0.025': 11.14,\n     '0.01': 13.28,\n     '0.005': 14.86 },\n  '5':\n   { '0.995': 0.41,\n     '0.99': 0.55,\n     '0.975': 0.83,\n     '0.95': 1.15,\n     '0.9': 1.61,\n     '0.5': 4.35,\n     '0.1': 9.24,\n     '0.05': 11.07,\n     '0.025': 12.83,\n     '0.01': 15.09,\n     '0.005': 16.75 },\n  '6':\n   { '0.995': 0.68,\n     '0.99': 0.87,\n     '0.975': 1.24,\n     '0.95': 1.64,\n     '0.9': 2.2,\n     '0.5': 5.35,\n     '0.1': 10.65,\n     '0.05': 12.59,\n     '0.025': 14.45,\n     '0.01': 16.81,\n     '0.005': 18.55 },\n  '7':\n   { '0.995': 0.99,\n     '0.99': 1.25,\n     '0.975': 1.69,\n     '0.95': 2.17,\n     '0.9': 2.83,\n     '0.5': 6.35,\n     '0.1': 12.02,\n     '0.05': 14.07,\n     '0.025': 16.01,\n     '0.01': 18.48,\n     '0.005': 20.28 },\n  '8':\n   { '0.995': 1.34,\n     '0.99': 1.65,\n     '0.975': 2.18,\n     '0.95': 2.73,\n     '0.9': 3.49,\n     '0.5': 7.34,\n     '0.1': 13.36,\n     '0.05': 15.51,\n     '0.025': 17.53,\n     '0.01': 20.09,\n     '0.005': 21.96 },\n  '9':\n   { '0.995': 1.73,\n     '0.99': 2.09,\n     '0.975': 2.7,\n     '0.95': 3.33,\n     '0.9': 4.17,\n     '0.5': 8.34,\n     '0.1': 14.68,\n     '0.05': 16.92,\n     '0.025': 19.02,\n     '0.01': 21.67,\n     '0.005': 23.59 },\n  '10':\n   { '0.995': 2.16,\n     '0.99': 2.56,\n     '0.975': 3.25,\n     '0.95': 3.94,\n     '0.9': 4.87,\n     '0.5': 9.34,\n     '0.1': 15.99,\n     '0.05': 18.31,\n     '0.025': 20.48,\n     '0.01': 23.21,\n     '0.005': 25.19 },\n  '11':\n   { '0.995': 2.6,\n     '0.99': 3.05,\n     '0.975': 3.82,\n     '0.95': 4.57,\n     '0.9': 5.58,\n     '0.5': 10.34,\n     '0.1': 17.28,\n     '0.05': 19.68,\n     '0.025': 21.92,\n     '0.01': 24.72,\n     '0.005': 26.76 },\n  '12':\n   { '0.995': 3.07,\n     '0.99': 3.57,\n     '0.975': 4.4,\n     '0.95': 5.23,\n     '0.9': 6.3,\n     '0.5': 11.34,\n     '0.1': 18.55,\n     '0.05': 21.03,\n     '0.025': 23.34,\n     '0.01': 26.22,\n     '0.005': 28.3 },\n  '13':\n   { '0.995': 3.57,\n     '0.99': 4.11,\n     '0.975': 5.01,\n     '0.95': 5.89,\n     '0.9': 7.04,\n     '0.5': 12.34,\n     '0.1': 19.81,\n     '0.05': 22.36,\n     '0.025': 24.74,\n     '0.01': 27.69,\n     '0.005': 29.82 },\n  '14':\n   { '0.995': 4.07,\n     '0.99': 4.66,\n     '0.975': 5.63,\n     '0.95': 6.57,\n     '0.9': 7.79,\n     '0.5': 13.34,\n     '0.1': 21.06,\n     '0.05': 23.68,\n     '0.025': 26.12,\n     '0.01': 29.14,\n     '0.005': 31.32 },\n  '15':\n   { '0.995': 4.6,\n     '0.99': 5.23,\n     '0.975': 6.27,\n     '0.95': 7.26,\n     '0.9': 8.55,\n     '0.5': 14.34,\n     '0.1': 22.31,\n     '0.05': 25,\n     '0.025': 27.49,\n     '0.01': 30.58,\n     '0.005': 32.8 },\n  '16':\n   { '0.995': 5.14,\n     '0.99': 5.81,\n     '0.975': 6.91,\n     '0.95': 7.96,\n     '0.9': 9.31,\n     '0.5': 15.34,\n     '0.1': 23.54,\n     '0.05': 26.3,\n     '0.025': 28.85,\n     '0.01': 32,\n     '0.005': 34.27 },\n  '17':\n   { '0.995': 5.7,\n     '0.99': 6.41,\n     '0.975': 7.56,\n     '0.95': 8.67,\n     '0.9': 10.09,\n     '0.5': 16.34,\n     '0.1': 24.77,\n     '0.05': 27.59,\n     '0.025': 30.19,\n     '0.01': 33.41,\n     '0.005': 35.72 },\n  '18':\n   { '0.995': 6.26,\n     '0.99': 7.01,\n     '0.975': 8.23,\n     '0.95': 9.39,\n     '0.9': 10.87,\n     '0.5': 17.34,\n     '0.1': 25.99,\n     '0.05': 28.87,\n     '0.025': 31.53,\n     '0.01': 34.81,\n     '0.005': 37.16 },\n  '19':\n   { '0.995': 6.84,\n     '0.99': 7.63,\n     '0.975': 8.91,\n     '0.95': 10.12,\n     '0.9': 11.65,\n     '0.5': 18.34,\n     '0.1': 27.2,\n     '0.05': 30.14,\n     '0.025': 32.85,\n     '0.01': 36.19,\n     '0.005': 38.58 },\n  '20':\n   { '0.995': 7.43,\n     '0.99': 8.26,\n     '0.975': 9.59,\n     '0.95': 10.85,\n     '0.9': 12.44,\n     '0.5': 19.34,\n     '0.1': 28.41,\n     '0.05': 31.41,\n     '0.025': 34.17,\n     '0.01': 37.57,\n     '0.005': 40 },\n  '21':\n   { '0.995': 8.03,\n     '0.99': 8.9,\n     '0.975': 10.28,\n     '0.95': 11.59,\n     '0.9': 13.24,\n     '0.5': 20.34,\n     '0.1': 29.62,\n     '0.05': 32.67,\n     '0.025': 35.48,\n     '0.01': 38.93,\n     '0.005': 41.4 },\n  '22':\n   { '0.995': 8.64,\n     '0.99': 9.54,\n     '0.975': 10.98,\n     '0.95': 12.34,\n     '0.9': 14.04,\n     '0.5': 21.34,\n     '0.1': 30.81,\n     '0.05': 33.92,\n     '0.025': 36.78,\n     '0.01': 40.29,\n     '0.005': 42.8 },\n  '23':\n   { '0.995': 9.26,\n     '0.99': 10.2,\n     '0.975': 11.69,\n     '0.95': 13.09,\n     '0.9': 14.85,\n     '0.5': 22.34,\n     '0.1': 32.01,\n     '0.05': 35.17,\n     '0.025': 38.08,\n     '0.01': 41.64,\n     '0.005': 44.18 },\n  '24':\n   { '0.995': 9.89,\n     '0.99': 10.86,\n     '0.975': 12.4,\n     '0.95': 13.85,\n     '0.9': 15.66,\n     '0.5': 23.34,\n     '0.1': 33.2,\n     '0.05': 36.42,\n     '0.025': 39.36,\n     '0.01': 42.98,\n     '0.005': 45.56 },\n  '25':\n   { '0.995': 10.52,\n     '0.99': 11.52,\n     '0.975': 13.12,\n     '0.95': 14.61,\n     '0.9': 16.47,\n     '0.5': 24.34,\n     '0.1': 34.28,\n     '0.05': 37.65,\n     '0.025': 40.65,\n     '0.01': 44.31,\n     '0.005': 46.93 },\n  '26':\n   { '0.995': 11.16,\n     '0.99': 12.2,\n     '0.975': 13.84,\n     '0.95': 15.38,\n     '0.9': 17.29,\n     '0.5': 25.34,\n     '0.1': 35.56,\n     '0.05': 38.89,\n     '0.025': 41.92,\n     '0.01': 45.64,\n     '0.005': 48.29 },\n  '27':\n   { '0.995': 11.81,\n     '0.99': 12.88,\n     '0.975': 14.57,\n     '0.95': 16.15,\n     '0.9': 18.11,\n     '0.5': 26.34,\n     '0.1': 36.74,\n     '0.05': 40.11,\n     '0.025': 43.19,\n     '0.01': 46.96,\n     '0.005': 49.65 },\n  '28':\n   { '0.995': 12.46,\n     '0.99': 13.57,\n     '0.975': 15.31,\n     '0.95': 16.93,\n     '0.9': 18.94,\n     '0.5': 27.34,\n     '0.1': 37.92,\n     '0.05': 41.34,\n     '0.025': 44.46,\n     '0.01': 48.28,\n     '0.005': 50.99 },\n  '29':\n   { '0.995': 13.12,\n     '0.99': 14.26,\n     '0.975': 16.05,\n     '0.95': 17.71,\n     '0.9': 19.77,\n     '0.5': 28.34,\n     '0.1': 39.09,\n     '0.05': 42.56,\n     '0.025': 45.72,\n     '0.01': 49.59,\n     '0.005': 52.34 },\n  '30':\n   { '0.995': 13.79,\n     '0.99': 14.95,\n     '0.975': 16.79,\n     '0.95': 18.49,\n     '0.9': 20.6,\n     '0.5': 29.34,\n     '0.1': 40.26,\n     '0.05': 43.77,\n     '0.025': 46.98,\n     '0.01': 50.89,\n     '0.005': 53.67 },\n  '40':\n   { '0.995': 20.71,\n     '0.99': 22.16,\n     '0.975': 24.43,\n     '0.95': 26.51,\n     '0.9': 29.05,\n     '0.5': 39.34,\n     '0.1': 51.81,\n     '0.05': 55.76,\n     '0.025': 59.34,\n     '0.01': 63.69,\n     '0.005': 66.77 },\n  '50':\n   { '0.995': 27.99,\n     '0.99': 29.71,\n     '0.975': 32.36,\n     '0.95': 34.76,\n     '0.9': 37.69,\n     '0.5': 49.33,\n     '0.1': 63.17,\n     '0.05': 67.5,\n     '0.025': 71.42,\n     '0.01': 76.15,\n     '0.005': 79.49 },\n  '60':\n   { '0.995': 35.53,\n     '0.99': 37.48,\n     '0.975': 40.48,\n     '0.95': 43.19,\n     '0.9': 46.46,\n     '0.5': 59.33,\n     '0.1': 74.4,\n     '0.05': 79.08,\n     '0.025': 83.3,\n     '0.01': 88.38,\n     '0.005': 91.95 },\n  '70':\n   { '0.995': 43.28,\n     '0.99': 45.44,\n     '0.975': 48.76,\n     '0.95': 51.74,\n     '0.9': 55.33,\n     '0.5': 69.33,\n     '0.1': 85.53,\n     '0.05': 90.53,\n     '0.025': 95.02,\n     '0.01': 100.42,\n     '0.005': 104.22 },\n  '80':\n   { '0.995': 51.17,\n     '0.99': 53.54,\n     '0.975': 57.15,\n     '0.95': 60.39,\n     '0.9': 64.28,\n     '0.5': 79.33,\n     '0.1': 96.58,\n     '0.05': 101.88,\n     '0.025': 106.63,\n     '0.01': 112.33,\n     '0.005': 116.32 },\n  '90':\n   { '0.995': 59.2,\n     '0.99': 61.75,\n     '0.975': 65.65,\n     '0.95': 69.13,\n     '0.9': 73.29,\n     '0.5': 89.33,\n     '0.1': 107.57,\n     '0.05': 113.14,\n     '0.025': 118.14,\n     '0.01': 124.12,\n     '0.005': 128.3 },\n  '100':\n   { '0.995': 67.33,\n     '0.99': 70.06,\n     '0.975': 74.22,\n     '0.95': 77.93,\n     '0.9': 82.36,\n     '0.5': 99.33,\n     '0.1': 118.5,\n     '0.05': 124.34,\n     '0.025': 129.56,\n     '0.01': 135.81,\n     '0.005': 140.17 } };\n\nmodule.exports = chiSquaredDistributionTable;\n",
    "'use strict';\n/* @flow */\n\nvar mean = require(22);\nvar chiSquaredDistributionTable = require(5);\n\n/**\n * The [χ2 (Chi-Squared) Goodness-of-Fit Test](http://en.wikipedia.org/wiki/Goodness_of_fit#Pearson.27s_chi-squared_test)\n * uses a measure of goodness of fit which is the sum of differences between observed and expected outcome frequencies\n * (that is, counts of observations), each squared and divided by the number of observations expected given the\n * hypothesized distribution. The resulting χ2 statistic, `chiSquared`, can be compared to the chi-squared distribution\n * to determine the goodness of fit. In order to determine the degrees of freedom of the chi-squared distribution, one\n * takes the total number of observed frequencies and subtracts the number of estimated parameters. The test statistic\n * follows, approximately, a chi-square distribution with (k − c) degrees of freedom where `k` is the number of non-empty\n * cells and `c` is the number of estimated parameters for the distribution.\n *\n * @param {Array<number>} data\n * @param {Function} distributionType a function that returns a point in a distribution:\n * for instance, binomial, bernoulli, or poisson\n * @param {number} significance\n * @returns {number} chi squared goodness of fit\n * @example\n * // Data from Poisson goodness-of-fit example 10-19 in William W. Hines & Douglas C. Montgomery,\n * // \"Probability and Statistics in Engineering and Management Science\", Wiley (1980).\n * var data1019 = [\n *     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n *     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n *     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n *     2, 2, 2, 2, 2, 2, 2, 2, 2,\n *     3, 3, 3, 3\n * ];\n * ss.chiSquaredGoodnessOfFit(data1019, ss.poissonDistribution, 0.05)); //= false\n */\nfunction chiSquaredGoodnessOfFit(\n    data/*: Array<number> */,\n    distributionType/*: Function */,\n    significance/*: number */)/*: boolean */ {\n    // Estimate from the sample data, a weighted mean.\n    var inputMean = mean(data),\n        // Calculated value of the χ2 statistic.\n        chiSquared = 0,\n        // Degrees of freedom, calculated as (number of class intervals -\n        // number of hypothesized distribution parameters estimated - 1)\n        degreesOfFreedom,\n        // Number of hypothesized distribution parameters estimated, expected to be supplied in the distribution test.\n        // Lose one degree of freedom for estimating `lambda` from the sample data.\n        c = 1,\n        // The hypothesized distribution.\n        // Generate the hypothesized distribution.\n        hypothesizedDistribution = distributionType(inputMean),\n        observedFrequencies = [],\n        expectedFrequencies = [],\n        k;\n\n    // Create an array holding a histogram from the sample data, of\n    // the form `{ value: numberOfOcurrences }`\n    for (var i = 0; i < data.length; i++) {\n        if (observedFrequencies[data[i]] === undefined) {\n            observedFrequencies[data[i]] = 0;\n        }\n        observedFrequencies[data[i]]++;\n    }\n\n    // The histogram we created might be sparse - there might be gaps\n    // between values. So we iterate through the histogram, making\n    // sure that instead of undefined, gaps have 0 values.\n    for (i = 0; i < observedFrequencies.length; i++) {\n        if (observedFrequencies[i] === undefined) {\n            observedFrequencies[i] = 0;\n        }\n    }\n\n    // Create an array holding a histogram of expected data given the\n    // sample size and hypothesized distribution.\n    for (k in hypothesizedDistribution) {\n        if (k in observedFrequencies) {\n            expectedFrequencies[+k] = hypothesizedDistribution[k] * data.length;\n        }\n    }\n\n    // Working backward through the expected frequencies, collapse classes\n    // if less than three observations are expected for a class.\n    // This transformation is applied to the observed frequencies as well.\n    for (k = expectedFrequencies.length - 1; k >= 0; k--) {\n        if (expectedFrequencies[k] < 3) {\n            expectedFrequencies[k - 1] += expectedFrequencies[k];\n            expectedFrequencies.pop();\n\n            observedFrequencies[k - 1] += observedFrequencies[k];\n            observedFrequencies.pop();\n        }\n    }\n\n    // Iterate through the squared differences between observed & expected\n    // frequencies, accumulating the `chiSquared` statistic.\n    for (k = 0; k < observedFrequencies.length; k++) {\n        chiSquared += Math.pow(\n            observedFrequencies[k] - expectedFrequencies[k], 2) /\n            expectedFrequencies[k];\n    }\n\n    // Calculate degrees of freedom for this test and look it up in the\n    // `chiSquaredDistributionTable` in order to\n    // accept or reject the goodness-of-fit of the hypothesized distribution.\n    degreesOfFreedom = observedFrequencies.length - c - 1;\n    return chiSquaredDistributionTable[degreesOfFreedom][significance] < chiSquared;\n}\n\nmodule.exports = chiSquaredGoodnessOfFit;\n",
    "'use strict';\n/* @flow */\n\n/**\n * Split an array into chunks of a specified size. This function\n * has the same behavior as [PHP's array_chunk](http://php.net/manual/en/function.array-chunk.php)\n * function, and thus will insert smaller-sized chunks at the end if\n * the input size is not divisible by the chunk size.\n *\n * `sample` is expected to be an array, and `chunkSize` a number.\n * The `sample` array can contain any kind of data.\n *\n * @param {Array} sample any array of values\n * @param {number} chunkSize size of each output array\n * @returns {Array<Array>} a chunked array\n * @example\n * console.log(chunk([1, 2, 3, 4], 2)); // [[1, 2], [3, 4]]\n */\nfunction chunk(sample/*:Array<any>*/, chunkSize/*:number*/)/*:?Array<Array<any>>*/ {\n\n    // a list of result chunks, as arrays in an array\n    var output = [];\n\n    // `chunkSize` must be zero or higher - otherwise the loop below,\n    // in which we call `start += chunkSize`, will loop infinitely.\n    // So, we'll detect and throw in that case to indicate\n    // invalid input.\n    if (chunkSize <= 0) {\n        throw new Error('chunk size must be a positive integer');\n    }\n\n    // `start` is the index at which `.slice` will start selecting\n    // new array elements\n    for (var start = 0; start < sample.length; start += chunkSize) {\n\n        // for each chunk, slice that part of the array and add it\n        // to the output. The `.slice` function does not change\n        // the original array.\n        output.push(sample.slice(start, start + chunkSize));\n    }\n    return output;\n}\n\nmodule.exports = chunk;\n",
    "'use strict';\n/* @flow */\n\nvar sortedUniqueCount = require(46),\n    numericSort = require(29);\n\n/**\n * Create a new column x row matrix.\n *\n * @private\n * @param {number} columns\n * @param {number} rows\n * @return {Array<Array<number>>} matrix\n * @example\n * makeMatrix(10, 10);\n */\nfunction makeMatrix(columns, rows) {\n    var matrix = [];\n    for (var i = 0; i < columns; i++) {\n        var column = [];\n        for (var j = 0; j < rows; j++) {\n            column.push(0);\n        }\n        matrix.push(column);\n    }\n    return matrix;\n}\n\n/**\n * Ckmeans clustering is an improvement on heuristic-based clustering\n * approaches like Jenks. The algorithm was developed in\n * [Haizhou Wang and Mingzhou Song](http://journal.r-project.org/archive/2011-2/RJournal_2011-2_Wang+Song.pdf)\n * as a [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) approach\n * to the problem of clustering numeric data into groups with the least\n * within-group sum-of-squared-deviations.\n *\n * Minimizing the difference within groups - what Wang & Song refer to as\n * `withinss`, or within sum-of-squares, means that groups are optimally\n * homogenous within and the data is split into representative groups.\n * This is very useful for visualization, where you may want to represent\n * a continuous variable in discrete color or style groups. This function\n * can provide groups that emphasize differences between data.\n *\n * Being a dynamic approach, this algorithm is based on two matrices that\n * store incrementally-computed values for squared deviations and backtracking\n * indexes.\n *\n * Unlike the [original implementation](https://cran.r-project.org/web/packages/Ckmeans.1d.dp/index.html),\n * this implementation does not include any code to automatically determine\n * the optimal number of clusters: this information needs to be explicitly\n * provided.\n *\n * ### References\n * _Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension by Dynamic\n * Programming_ Haizhou Wang and Mingzhou Song ISSN 2073-4859\n *\n * from The R Journal Vol. 3/2, December 2011\n * @param {Array<number>} data input data, as an array of number values\n * @param {number} nClusters number of desired classes. This cannot be\n * greater than the number of values in the data array.\n * @returns {Array<Array<number>>} clustered input\n * @example\n * ckmeans([-1, 2, -1, 2, 4, 5, 6, -1, 2, -1], 3);\n * // The input, clustered into groups of similar numbers.\n * //= [[-1, -1, -1, -1], [2, 2, 2], [4, 5, 6]]);\n */\nfunction ckmeans(data/*: Array<number> */, nClusters/*: number */)/*: Array<Array<number>> */ {\n\n    if (nClusters > data.length) {\n        throw new Error('Cannot generate more classes than there are data values');\n    }\n\n    var sorted = numericSort(data),\n        // we'll use this as the maximum number of clusters\n        uniqueCount = sortedUniqueCount(sorted);\n\n    // if all of the input values are identical, there's one cluster\n    // with all of the input in it.\n    if (uniqueCount === 1) {\n        return [sorted];\n    }\n\n    // named 'D' originally\n    var matrix = makeMatrix(nClusters, sorted.length),\n        // named 'B' originally\n        backtrackMatrix = makeMatrix(nClusters, sorted.length);\n\n    // This is a dynamic programming way to solve the problem of minimizing\n    // within-cluster sum of squares. It's similar to linear regression\n    // in this way, and this calculation incrementally computes the\n    // sum of squares that are later read.\n\n    // The outer loop iterates through clusters, from 0 to nClusters.\n    for (var cluster = 0; cluster < nClusters; cluster++) {\n\n        // At the start of each loop, the mean starts as the first element\n        var firstClusterMean = sorted[0];\n\n        for (var sortedIdx = Math.max(cluster, 1);\n             sortedIdx < sorted.length;\n             sortedIdx++) {\n\n            if (cluster === 0) {\n\n                // Increase the running sum of squares calculation by this\n                // new value\n                var squaredDifference = Math.pow(\n                    sorted[sortedIdx] - firstClusterMean, 2);\n                matrix[cluster][sortedIdx] = matrix[cluster][sortedIdx - 1] +\n                    (sortedIdx / (sortedIdx + 1)) * squaredDifference;\n\n                // We're computing a running mean by taking the previous\n                // mean value, multiplying it by the number of elements\n                // seen so far, and then dividing it by the number of\n                // elements total.\n                var newSum = sortedIdx * firstClusterMean + sorted[sortedIdx];\n                firstClusterMean = newSum / (sortedIdx + 1);\n\n            } else {\n\n                var sumSquaredDistances = 0,\n                    meanXJ = 0;\n\n                for (var j = sortedIdx; j >= cluster; j--) {\n\n                    sumSquaredDistances += (sortedIdx - j) /\n                        (sortedIdx - j + 1) *\n                        Math.pow(sorted[j] - meanXJ, 2);\n\n                    meanXJ = (sorted[j] + (sortedIdx - j) * meanXJ) /\n                        (sortedIdx - j + 1);\n\n                    if (j === sortedIdx) {\n                        matrix[cluster][sortedIdx] = sumSquaredDistances;\n                        backtrackMatrix[cluster][sortedIdx] = j;\n                        if (j > 0) {\n                            matrix[cluster][sortedIdx] += matrix[cluster - 1][j - 1];\n                        }\n                    } else {\n                        if (j === 0) {\n                            if (sumSquaredDistances <= matrix[cluster][sortedIdx]) {\n                                matrix[cluster][sortedIdx] = sumSquaredDistances;\n                                backtrackMatrix[cluster][sortedIdx] = j;\n                            }\n                        } else if (sumSquaredDistances + matrix[cluster - 1][j - 1] < matrix[cluster][sortedIdx]) {\n                            matrix[cluster][sortedIdx] = sumSquaredDistances + matrix[cluster - 1][j - 1];\n                            backtrackMatrix[cluster][sortedIdx] = j;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // The real work of Ckmeans clustering happens in the matrix generation:\n    // the generated matrices encode all possible clustering combinations, and\n    // once they're generated we can solve for the best clustering groups\n    // very quickly.\n    var clusters = [],\n        clusterRight = backtrackMatrix[0].length - 1;\n\n    // Backtrack the clusters from the dynamic programming matrix. This\n    // starts at the bottom-right corner of the matrix (if the top-left is 0, 0),\n    // and moves the cluster target with the loop.\n    for (cluster = backtrackMatrix.length - 1; cluster >= 0; cluster--) {\n\n        var clusterLeft = backtrackMatrix[cluster][clusterRight];\n\n        // fill the cluster from the sorted input by taking a slice of the\n        // array. the backtrack matrix makes this easy - it stores the\n        // indexes where the cluster should start and end.\n        clusters[cluster] = sorted.slice(clusterLeft, clusterRight + 1);\n\n        if (cluster > 0) {\n            clusterRight = clusterLeft - 1;\n        }\n    }\n\n    return clusters;\n}\n\nmodule.exports = ckmeans;\n",
    "'use strict';\n/* @flow */\n\nvar standardNormalTable = require(48);\n\n/**\n * **[Cumulative Standard Normal Probability](http://en.wikipedia.org/wiki/Standard_normal_table)**\n *\n * Since probability tables cannot be\n * printed for every normal distribution, as there are an infinite variety\n * of normal distributions, it is common practice to convert a normal to a\n * standard normal and then use the standard normal table to find probabilities.\n *\n * You can use `.5 + .5 * errorFunction(x / Math.sqrt(2))` to calculate the probability\n * instead of looking it up in a table.\n *\n * @param {number} z\n * @returns {number} cumulative standard normal probability\n */\nfunction cumulativeStdNormalProbability(z /*:number */)/*:number */ {\n\n    // Calculate the position of this value.\n    var absZ = Math.abs(z),\n        // Each row begins with a different\n        // significant digit: 0.5, 0.6, 0.7, and so on. Each value in the table\n        // corresponds to a range of 0.01 in the input values, so the value is\n        // multiplied by 100.\n        index = Math.min(Math.round(absZ * 100), standardNormalTable.length - 1);\n\n    // The index we calculate must be in the table as a positive value,\n    // but we still pay attention to whether the input is positive\n    // or negative, and flip the output value as a last step.\n    if (z >= 0) {\n        return standardNormalTable[index];\n    } else {\n        // due to floating-point arithmetic, values in the table with\n        // 4 significant figures can nevertheless end up as repeating\n        // fractions when they're computed here.\n        return +(1 - standardNormalTable[index]).toFixed(4);\n    }\n}\n\nmodule.exports = cumulativeStdNormalProbability;\n",
    "'use strict';\n/* @flow */\n\n/**\n * We use `ε`, epsilon, as a stopping criterion when we want to iterate\n * until we're \"close enough\". Epsilon is a very small number: for\n * simple statistics, that number is **0.0001**\n *\n * This is used in calculations like the binomialDistribution, in which\n * the process of finding a value is [iterative](https://en.wikipedia.org/wiki/Iterative_method):\n * it progresses until it is close enough.\n *\n * Below is an example of using epsilon in [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent),\n * where we're trying to find a local minimum of a function's derivative,\n * given by the `fDerivative` method.\n *\n * @example\n * // From calculation, we expect that the local minimum occurs at x=9/4\n * var x_old = 0;\n * // The algorithm starts at x=6\n * var x_new = 6;\n * var stepSize = 0.01;\n *\n * function fDerivative(x) {\n *   return 4 * Math.pow(x, 3) - 9 * Math.pow(x, 2);\n * }\n *\n * // The loop runs until the difference between the previous\n * // value and the current value is smaller than epsilon - a rough\n * // meaure of 'close enough'\n * while (Math.abs(x_new - x_old) > ss.epsilon) {\n *   x_old = x_new;\n *   x_new = x_old - stepSize * fDerivative(x_old);\n * }\n *\n * console.log('Local minimum occurs at', x_new);\n */\nvar epsilon = 0.0001;\n\nmodule.exports = epsilon;\n",
    "'use strict';\n/* @flow */\n\nvar max = require(21),\n    min = require(25);\n\n/**\n * Given an array of data, this will find the extent of the\n * data and return an array of breaks that can be used\n * to categorize the data into a number of classes. The\n * returned array will always be 1 longer than the number of\n * classes because it includes the minimum value.\n *\n * @param {Array<number>} data input data, as an array of number values\n * @param {number} nClasses number of desired classes\n * @returns {Array<number>} array of class break positions\n * @example\n * equalIntervalBreaks([1, 2, 3, 4, 5, 6], 4); //= [1, 2.25, 3.5, 4.75, 6]\n */\nfunction equalIntervalBreaks(data/*: Array<number> */, nClasses/*:number*/)/*: Array<number> */ {\n\n    if (data.length <= 1) {\n        return data;\n    }\n\n    var theMin = min(data),\n        theMax = max(data); \n\n    // the first break will always be the minimum value\n    // in the dataset\n    var breaks = [theMin];\n\n    // The size of each break is the full range of the data\n    // divided by the number of classes requested\n    var breakSize = (theMax - theMin) / nClasses;\n\n    // In the case of nClasses = 1, this loop won't run\n    // and the returned breaks will be [min, max]\n    for (var i = 1; i < nClasses; i++) {\n        breaks.push(breaks[0] + breakSize * i);\n    }\n\n    // the last break will always be the\n    // maximum.\n    breaks.push(theMax);\n\n    return breaks;\n}\n\nmodule.exports = equalIntervalBreaks;\n",
    "'use strict';\n/* @flow */\n\n/**\n * **[Gaussian error function](http://en.wikipedia.org/wiki/Error_function)**\n *\n * The `errorFunction(x/(sd * Math.sqrt(2)))` is the probability that a value in a\n * normal distribution with standard deviation sd is within x of the mean.\n *\n * This function returns a numerical approximation to the exact value.\n *\n * @param {number} x input\n * @return {number} error estimation\n * @example\n * errorFunction(1); //= 0.8427\n */\nfunction errorFunction(x/*: number */)/*: number */ {\n    var t = 1 / (1 + 0.5 * Math.abs(x));\n    var tau = t * Math.exp(-Math.pow(x, 2) -\n        1.26551223 +\n        1.00002368 * t +\n        0.37409196 * Math.pow(t, 2) +\n        0.09678418 * Math.pow(t, 3) -\n        0.18628806 * Math.pow(t, 4) +\n        0.27886807 * Math.pow(t, 5) -\n        1.13520398 * Math.pow(t, 6) +\n        1.48851587 * Math.pow(t, 7) -\n        0.82215223 * Math.pow(t, 8) +\n        0.17087277 * Math.pow(t, 9));\n    if (x >= 0) {\n        return 1 - tau;\n    } else {\n        return tau - 1;\n    }\n}\n\nmodule.exports = errorFunction;\n",
    "'use strict';\n/* @flow */\n\n/**\n * A [Factorial](https://en.wikipedia.org/wiki/Factorial), usually written n!, is the product of all positive\n * integers less than or equal to n. Often factorial is implemented\n * recursively, but this iterative approach is significantly faster\n * and simpler.\n *\n * @param {number} n input\n * @returns {number} factorial: n!\n * @example\n * console.log(factorial(5)); // 120\n */\nfunction factorial(n /*: number */)/*: number */ {\n\n    // factorial is mathematically undefined for negative numbers\n    if (n < 0) { return NaN; }\n\n    // typically you'll expand the factorial function going down, like\n    // 5! = 5 * 4 * 3 * 2 * 1. This is going in the opposite direction,\n    // counting from 2 up to the number in question, and since anything\n    // multiplied by 1 is itself, the loop only needs to start at 2.\n    var accumulator = 1;\n    for (var i = 2; i <= n; i++) {\n        // for each number up to and including the number `n`, multiply\n        // the accumulator my that number.\n        accumulator *= i;\n    }\n    return accumulator;\n}\n\nmodule.exports = factorial;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [Geometric Mean](https://en.wikipedia.org/wiki/Geometric_mean) is\n * a mean function that is more useful for numbers in different\n * ranges.\n *\n * This is the nth root of the input numbers multiplied by each other.\n *\n * The geometric mean is often useful for\n * **[proportional growth](https://en.wikipedia.org/wiki/Geometric_mean#Proportional_growth)**: given\n * growth rates for multiple years, like _80%, 16.66% and 42.85%_, a simple\n * mean will incorrectly estimate an average growth rate, whereas a geometric\n * mean will correctly estimate a growth rate that, over those years,\n * will yield the same end value.\n *\n * This runs on `O(n)`, linear time in respect to the array\n *\n * @param {Array<number>} x input array\n * @returns {number} geometric mean\n * @example\n * var growthRates = [1.80, 1.166666, 1.428571];\n * var averageGrowth = geometricMean(growthRates);\n * var averageGrowthRates = [averageGrowth, averageGrowth, averageGrowth];\n * var startingValue = 10;\n * var startingValueMean = 10;\n * growthRates.forEach(function(rate) {\n *   startingValue *= rate;\n * });\n * averageGrowthRates.forEach(function(rate) {\n *   startingValueMean *= rate;\n * });\n * startingValueMean === startingValue;\n */\nfunction geometricMean(x /*: Array<number> */) {\n    // The mean of no numbers is null\n    if (x.length === 0) { return undefined; }\n\n    // the starting value.\n    var value = 1;\n\n    for (var i = 0; i < x.length; i++) {\n        // the geometric mean is only valid for positive numbers\n        if (x[i] <= 0) { return undefined; }\n\n        // repeatedly multiply the value by each number\n        value *= x[i];\n    }\n\n    return Math.pow(value, 1 / x.length);\n}\n\nmodule.exports = geometricMean;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [Harmonic Mean](https://en.wikipedia.org/wiki/Harmonic_mean) is\n * a mean function typically used to find the average of rates.\n * This mean is calculated by taking the reciprocal of the arithmetic mean\n * of the reciprocals of the input numbers.\n *\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs on `O(n)`, linear time in respect to the array.\n *\n * @param {Array<number>} x input\n * @returns {number} harmonic mean\n * @example\n * ss.harmonicMean([2, 3]) //= 2.4\n */\nfunction harmonicMean(x /*: Array<number> */) {\n    // The mean of no numbers is null\n    if (x.length === 0) { return undefined; }\n\n    var reciprocalSum = 0;\n\n    for (var i = 0; i < x.length; i++) {\n        // the harmonic mean is only valid for positive numbers\n        if (x[i] <= 0) { return undefined; }\n\n        reciprocalSum += 1 / x[i];\n    }\n\n    // divide n by the the reciprocal sum\n    return x.length / reciprocalSum;\n}\n\nmodule.exports = harmonicMean;\n",
    "'use strict';\n/* @flow */\n\nvar quantile = require(34);\n\n/**\n * The [Interquartile range](http://en.wikipedia.org/wiki/Interquartile_range) is\n * a measure of statistical dispersion, or how scattered, spread, or\n * concentrated a distribution is. It's computed as the difference between\n * the third quartile and first quartile.\n *\n * @param {Array<number>} sample\n * @returns {number} interquartile range: the span between lower and upper quartile,\n * 0.25 and 0.75\n * @example\n * interquartileRange([0, 1, 2, 3]); //= 2\n */\nfunction interquartileRange(sample/*: Array<number> */) {\n    // Interquartile range is the span between the upper quartile,\n    // at `0.75`, and lower quartile, `0.25`\n    var q1 = quantile(sample, 0.75),\n        q2 = quantile(sample, 0.25);\n\n    if (typeof q1 === 'number' && typeof q2 === 'number') {\n        return q1 - q2;\n    }\n}\n\nmodule.exports = interquartileRange;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The Inverse [Gaussian error function](http://en.wikipedia.org/wiki/Error_function)\n * returns a numerical approximation to the value that would have caused\n * `errorFunction()` to return x.\n *\n * @param {number} x value of error function\n * @returns {number} estimated inverted value\n */\nfunction inverseErrorFunction(x/*: number */)/*: number */ {\n    var a = (8 * (Math.PI - 3)) / (3 * Math.PI * (4 - Math.PI));\n\n    var inv = Math.sqrt(Math.sqrt(\n        Math.pow(2 / (Math.PI * a) + Math.log(1 - x * x) / 2, 2) -\n        Math.log(1 - x * x) / a) -\n        (2 / (Math.PI * a) + Math.log(1 - x * x) / 2));\n\n    if (x >= 0) {\n        return inv;\n    } else {\n        return -inv;\n    }\n}\n\nmodule.exports = inverseErrorFunction;\n",
    "'use strict';\n/* @flow */\n\n/**\n * [Simple linear regression](http://en.wikipedia.org/wiki/Simple_linear_regression)\n * is a simple way to find a fitted line\n * between a set of coordinates. This algorithm finds the slope and y-intercept of a regression line\n * using the least sum of squares.\n *\n * @param {Array<Array<number>>} data an array of two-element of arrays,\n * like `[[0, 1], [2, 3]]`\n * @returns {Object} object containing slope and intersect of regression line\n * @example\n * linearRegression([[0, 0], [1, 1]]); // { m: 1, b: 0 }\n */\nfunction linearRegression(data/*: Array<Array<number>> */)/*: { m: number, b: number } */ {\n\n    var m, b;\n\n    // Store data length in a local variable to reduce\n    // repeated object property lookups\n    var dataLength = data.length;\n\n    //if there's only one point, arbitrarily choose a slope of 0\n    //and a y-intercept of whatever the y of the initial point is\n    if (dataLength === 1) {\n        m = 0;\n        b = data[0][1];\n    } else {\n        // Initialize our sums and scope the `m` and `b`\n        // variables that define the line.\n        var sumX = 0, sumY = 0,\n            sumXX = 0, sumXY = 0;\n\n        // Use local variables to grab point values\n        // with minimal object property lookups\n        var point, x, y;\n\n        // Gather the sum of all x values, the sum of all\n        // y values, and the sum of x^2 and (x*y) for each\n        // value.\n        //\n        // In math notation, these would be SS_x, SS_y, SS_xx, and SS_xy\n        for (var i = 0; i < dataLength; i++) {\n            point = data[i];\n            x = point[0];\n            y = point[1];\n\n            sumX += x;\n            sumY += y;\n\n            sumXX += x * x;\n            sumXY += x * y;\n        }\n\n        // `m` is the slope of the regression line\n        m = ((dataLength * sumXY) - (sumX * sumY)) /\n            ((dataLength * sumXX) - (sumX * sumX));\n\n        // `b` is the y-intercept of the line.\n        b = (sumY / dataLength) - ((m * sumX) / dataLength);\n    }\n\n    // Return both values as an object.\n    return {\n        m: m,\n        b: b\n    };\n}\n\n\nmodule.exports = linearRegression;\n",
    "'use strict';\n/* @flow */\n\n/**\n * Given the output of `linearRegression`: an object\n * with `m` and `b` values indicating slope and intercept,\n * respectively, generate a line function that translates\n * x values into y values.\n *\n * @param {Object} mb object with `m` and `b` members, representing\n * slope and intersect of desired line\n * @returns {Function} method that computes y-value at any given\n * x-value on the line.\n * @example\n * var l = linearRegressionLine(linearRegression([[0, 0], [1, 1]]));\n * l(0) //= 0\n * l(2) //= 2\n */\nfunction linearRegressionLine(mb/*: { b: number, m: number }*/)/*: Function */ {\n    // Return a function that computes a `y` value for each\n    // x value it is given, based on the values of `b` and `a`\n    // that we just computed.\n    return function(x) {\n        return mb.b + (mb.m * x);\n    };\n}\n\nmodule.exports = linearRegressionLine;\n",
    "'use strict';\n/* @flow */\n\nvar median = require(23);\n\n/**\n * The [Median Absolute Deviation](http://en.wikipedia.org/wiki/Median_absolute_deviation) is\n * a robust measure of statistical\n * dispersion. It is more resilient to outliers than the standard deviation.\n *\n * @param {Array<number>} x input array\n * @returns {number} median absolute deviation\n * @example\n * mad([1, 1, 2, 2, 4, 6, 9]); //= 1\n */\nfunction mad(x /*: Array<number> */) {\n    // The mad of nothing is null\n    var medianValue = median(x),\n        medianAbsoluteDeviations = [];\n\n    // Make a list of absolute deviations from the median\n    for (var i = 0; i < x.length; i++) {\n        medianAbsoluteDeviations.push(Math.abs(x[i] - medianValue));\n    }\n\n    // Find the median value of that list\n    return median(medianAbsoluteDeviations);\n}\n\nmodule.exports = mad;\n",
    "'use strict';\n/* @flow */\n\n/**\n * This computes the maximum number in an array.\n *\n * This runs on `O(n)`, linear time in respect to the array\n *\n * @param {Array<number>} x input\n * @returns {number} maximum value\n * @example\n * console.log(max([1, 2, 3, 4])); // 4\n */\nfunction max(x /*: Array<number> */) /*:number*/ {\n    var value;\n    for (var i = 0; i < x.length; i++) {\n        // On the first iteration of this loop, max is\n        // NaN and is thus made the maximum element in the array\n        if (value === undefined || x[i] > value) {\n            value = x[i];\n        }\n    }\n    if (value === undefined) {\n        return NaN;\n    }\n    return value;\n}\n\nmodule.exports = max;\n",
    "'use strict';\n/* @flow */\n\nvar sum = require(49);\n\n/**\n * The mean, _also known as average_,\n * is the sum of all values over the number of values.\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs on `O(n)`, linear time in respect to the array\n *\n * @param {Array<number>} x input values\n * @returns {number} mean\n * @example\n * console.log(mean([0, 10])); // 5\n */\nfunction mean(x /*: Array<number> */)/*:number*/ {\n    // The mean of no numbers is null\n    if (x.length === 0) { return NaN; }\n\n    return sum(x) / x.length;\n}\n\nmodule.exports = mean;\n",
    "'use strict';\n/* @flow */\n\nvar medianSorted = require(24),\n    numericSort = require(29);\n\n/**\n * The [median](http://en.wikipedia.org/wiki/Median) is\n * the middle number of a list. This is often a good indicator of 'the middle'\n * when there are outliers that skew the `mean()` value.\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * The median isn't necessarily one of the elements in the list: the value\n * can be the average of two elements if the list has an even length\n * and the two central values are different.\n *\n * @param {Array<number>} x input\n * @returns {number} median value\n * @example\n * var incomes = [10, 2, 5, 100, 2, 1];\n * median(incomes); //= 3.5\n */\nfunction median(x /*: Array<number> */)/*:number*/ {\n    // Sorting the array makes it easy to find the center, but\n    // use `.slice()` to ensure the original array `x` is not modified\n    return medianSorted(numericSort(x));\n}\n\nmodule.exports = median;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [median](http://en.wikipedia.org/wiki/Median) is\n * the middle number of a list. This is often a good indicator of 'the middle'\n * when there are outliers that skew the `mean()` value.\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * The median isn't necessarily one of the elements in the list: the value\n * can be the average of two elements if the list has an even length\n * and the two central values are different.\n *\n * @param {Array<number>} sorted input\n * @returns {number} median value\n * @example\n * var incomes = [10, 2, 5, 100, 2, 1];\n * median(incomes); //= 3.5\n */\nfunction medianSorted(sorted /*: Array<number> */)/*:number*/ {\n    // The median of an empty list is NaN\n    if (sorted.length === 0) { return NaN; }\n\n    // If the length of the list is odd, it's the central number\n    if (sorted.length % 2 === 1) {\n        return sorted[(sorted.length - 1) / 2];\n    // Otherwise, the median is the average of the two numbers\n    // at the center of the list\n    } else {\n        var a = sorted[sorted.length / 2 - 1];\n        var b = sorted[sorted.length / 2];\n        return (a + b) / 2;\n    }\n}\n\nmodule.exports = medianSorted;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The min is the lowest number in the array. This runs on `O(n)`, linear time in respect to the array\n *\n * @param {Array<number>} x input\n * @returns {number} minimum value\n * @example\n * min([1, 5, -10, 100, 2]); // -100\n */\nfunction min(x /*: Array<number> */)/*:number*/ {\n    var value;\n    for (var i = 0; i < x.length; i++) {\n        // On the first iteration of this loop, min is\n        // NaN and is thus made the minimum element in the array\n        if (value === undefined || x[i] < value) {\n            value = x[i];\n        }\n    }\n    if (value === undefined) {\n        return NaN;\n    }\n    return value;\n}\n\nmodule.exports = min;\n",
    "'use strict';\n/* @flow */\n\n/**\n * **Mixin** simple_statistics to a single Array instance if provided\n * or the Array native object if not. This is an optional\n * feature that lets you treat simple_statistics as a native feature\n * of Javascript.\n *\n * @param {Object} ss simple statistics\n * @param {Array} [array=] a single array instance which will be augmented\n * with the extra methods. If omitted, mixin will apply to all arrays\n * by changing the global `Array.prototype`.\n * @returns {*} the extended Array, or Array.prototype if no object\n * is given.\n *\n * @example\n * var myNumbers = [1, 2, 3];\n * mixin(ss, myNumbers);\n * console.log(myNumbers.sum()); // 6\n */\nfunction mixin(ss /*: Object */, array /*: ?Array<any> */)/*: any */ {\n    var support = !!(Object.defineProperty && Object.defineProperties);\n    // Coverage testing will never test this error.\n    /* istanbul ignore next */\n    if (!support) {\n        throw new Error('without defineProperty, simple-statistics cannot be mixed in');\n    }\n\n    // only methods which work on basic arrays in a single step\n    // are supported\n    var arrayMethods = ['median', 'standardDeviation', 'sum', 'product',\n        'sampleSkewness',\n        'mean', 'min', 'max', 'quantile', 'geometricMean',\n        'harmonicMean', 'root_mean_square'];\n\n    // create a closure with a method name so that a reference\n    // like `arrayMethods[i]` doesn't follow the loop increment\n    function wrap(method) {\n        return function() {\n            // cast any arguments into an array, since they're\n            // natively objects\n            var args = Array.prototype.slice.apply(arguments);\n            // make the first argument the array itself\n            args.unshift(this);\n            // return the result of the ss method\n            return ss[method].apply(ss, args);\n        };\n    }\n\n    // select object to extend\n    var extending;\n    if (array) {\n        // create a shallow copy of the array so that our internal\n        // operations do not change it by reference\n        extending = array.slice();\n    } else {\n        extending = Array.prototype;\n    }\n\n    // for each array function, define a function that gets\n    // the array as the first argument.\n    // We use [defineProperty](https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Global_Objects/Object/defineProperty)\n    // because it allows these properties to be non-enumerable:\n    // `for (var in x)` loops will not run into problems with this\n    // implementation.\n    for (var i = 0; i < arrayMethods.length; i++) {\n        Object.defineProperty(extending, arrayMethods[i], {\n            value: wrap(arrayMethods[i]),\n            configurable: true,\n            enumerable: false,\n            writable: true\n        });\n    }\n\n    return extending;\n}\n\nmodule.exports = mixin;\n",
    "'use strict';\n/* @flow */\n\nvar numericSort = require(29),\n    modeSorted = require(28);\n\n/**\n * The [mode](http://bit.ly/W5K4Yt) is the number that appears in a list the highest number of times.\n * There can be multiple modes in a list: in the event of a tie, this\n * algorithm will return the most recently seen mode.\n *\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs on `O(nlog(n))` because it needs to sort the array internally\n * before running an `O(n)` search to find the mode.\n *\n * @param {Array<number>} x input\n * @returns {number} mode\n * @example\n * mode([0, 0, 1]); //= 0\n */\nfunction mode(x /*: Array<number> */)/*:number*/ {\n    // Sorting the array lets us iterate through it below and be sure\n    // that every time we see a new number it's new and we'll never\n    // see the same number twice\n    return modeSorted(numericSort(x));\n}\n\nmodule.exports = mode;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [mode](http://bit.ly/W5K4Yt) is the number that appears in a list the highest number of times.\n * There can be multiple modes in a list: in the event of a tie, this\n * algorithm will return the most recently seen mode.\n *\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs in `O(n)` because the input is sorted.\n *\n * @param {Array<number>} sorted input\n * @returns {number} mode\n * @example\n * mode([0, 0, 1]); //= 0\n */\nfunction modeSorted(sorted /*: Array<number> */)/*:number*/ {\n\n    // Handle edge cases:\n    // The mode of an empty list is NaN\n    if (sorted.length === 0) { return NaN; }\n    else if (sorted.length === 1) { return sorted[0]; }\n\n    // This assumes it is dealing with an array of size > 1, since size\n    // 0 and 1 are handled immediately. Hence it starts at index 1 in the\n    // array.\n    var last = sorted[0],\n        // store the mode as we find new modes\n        value = NaN,\n        // store how many times we've seen the mode\n        maxSeen = 0,\n        // how many times the current candidate for the mode\n        // has been seen\n        seenThis = 1;\n\n    // end at sorted.length + 1 to fix the case in which the mode is\n    // the highest number that occurs in the sequence. the last iteration\n    // compares sorted[i], which is undefined, to the highest number\n    // in the series\n    for (var i = 1; i < sorted.length + 1; i++) {\n        // we're seeing a new number pass by\n        if (sorted[i] !== last) {\n            // the last number is the new mode since we saw it more\n            // often than the old one\n            if (seenThis > maxSeen) {\n                maxSeen = seenThis;\n                value = last;\n            }\n            seenThis = 1;\n            last = sorted[i];\n        // if this isn't a new number, it's one more occurrence of\n        // the potential mode\n        } else { seenThis++; }\n    }\n    return value;\n}\n\nmodule.exports = modeSorted;\n",
    "'use strict';\n/* @flow */\n\n/**\n * Sort an array of numbers by their numeric value, ensuring that the\n * array is not changed in place.\n *\n * This is necessary because the default behavior of .sort\n * in JavaScript is to sort arrays as string values\n *\n *     [1, 10, 12, 102, 20].sort()\n *     // output\n *     [1, 10, 102, 12, 20]\n *\n * @param {Array<number>} array input array\n * @return {Array<number>} sorted array\n * @private\n * @example\n * numericSort([3, 2, 1]) // [1, 2, 3]\n */\nfunction numericSort(array /*: Array<number> */) /*: Array<number> */ {\n    return array\n        // ensure the array is changed in-place\n        .slice()\n        // comparator function that treats input as numeric\n        .sort(function(a, b) {\n            return a - b;\n        });\n}\n\nmodule.exports = numericSort;\n",
    "'use strict';\n/* @flow */\n\n/**\n * This is a single-layer [Perceptron Classifier](http://en.wikipedia.org/wiki/Perceptron) that takes\n * arrays of numbers and predicts whether they should be classified\n * as either 0 or 1 (negative or positive examples).\n * @class\n * @example\n * // Create the model\n * var p = new PerceptronModel();\n * // Train the model with input with a diagonal boundary.\n * for (var i = 0; i < 5; i++) {\n *     p.train([1, 1], 1);\n *     p.train([0, 1], 0);\n *     p.train([1, 0], 0);\n *     p.train([0, 0], 0);\n * }\n * p.predict([0, 0]); // 0\n * p.predict([0, 1]); // 0\n * p.predict([1, 0]); // 0\n * p.predict([1, 1]); // 1\n */\nfunction PerceptronModel() {\n    // The weights, or coefficients of the model;\n    // weights are only populated when training with data.\n    this.weights = [];\n    // The bias term, or intercept; it is also a weight but\n    // it's stored separately for convenience as it is always\n    // multiplied by one.\n    this.bias = 0;\n}\n\n/**\n * **Predict**: Use an array of features with the weight array and bias\n * to predict whether an example is labeled 0 or 1.\n *\n * @param {Array<number>} features an array of features as numbers\n * @returns {number} 1 if the score is over 0, otherwise 0\n */\nPerceptronModel.prototype.predict = function(features) {\n\n    // Only predict if previously trained\n    // on the same size feature array(s).\n    if (features.length !== this.weights.length) { return null; }\n\n    // Calculate the sum of features times weights,\n    // with the bias added (implicitly times one).\n    var score = 0;\n    for (var i = 0; i < this.weights.length; i++) {\n        score += this.weights[i] * features[i];\n    }\n    score += this.bias;\n\n    // Classify as 1 if the score is over 0, otherwise 0.\n    if (score > 0) {\n        return 1;\n    } else {\n        return 0;\n    }\n};\n\n/**\n * **Train** the classifier with a new example, which is\n * a numeric array of features and a 0 or 1 label.\n *\n * @param {Array<number>} features an array of features as numbers\n * @param {number} label either 0 or 1\n * @returns {PerceptronModel} this\n */\nPerceptronModel.prototype.train = function(features, label) {\n    // Require that only labels of 0 or 1 are considered.\n    if (label !== 0 && label !== 1) { return null; }\n    // The length of the feature array determines\n    // the length of the weight array.\n    // The perceptron will continue learning as long as\n    // it keeps seeing feature arrays of the same length.\n    // When it sees a new data shape, it initializes.\n    if (features.length !== this.weights.length) {\n        this.weights = features;\n        this.bias = 1;\n    }\n    // Make a prediction based on current weights.\n    var prediction = this.predict(features);\n    // Update the weights if the prediction is wrong.\n    if (prediction !== label) {\n        var gradient = label - prediction;\n        for (var i = 0; i < this.weights.length; i++) {\n            this.weights[i] += gradient * features[i];\n        }\n        this.bias += gradient;\n    }\n    return this;\n};\n\nmodule.exports = PerceptronModel;\n",
    "'use strict';\n/* @flow */\n\nvar epsilon = require(10);\nvar factorial = require(13);\n\n/**\n * The [Poisson Distribution](http://en.wikipedia.org/wiki/Poisson_distribution)\n * is a discrete probability distribution that expresses the probability\n * of a given number of events occurring in a fixed interval of time\n * and/or space if these events occur with a known average rate and\n * independently of the time since the last event.\n *\n * The Poisson Distribution is characterized by the strictly positive\n * mean arrival or occurrence rate, `λ`.\n *\n * @param {number} lambda location poisson distribution\n * @returns {number} value of poisson distribution at that point\n */\nfunction poissonDistribution(lambda/*: number */) {\n    // Check that lambda is strictly positive\n    if (lambda <= 0) { return undefined; }\n\n    // our current place in the distribution\n    var x = 0,\n        // and we keep track of the current cumulative probability, in\n        // order to know when to stop calculating chances.\n        cumulativeProbability = 0,\n        // the calculated cells to be returned\n        cells = {};\n\n    // This algorithm iterates through each potential outcome,\n    // until the `cumulativeProbability` is very close to 1, at\n    // which point we've defined the vast majority of outcomes\n    do {\n        // a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function)\n        cells[x] = (Math.pow(Math.E, -lambda) * Math.pow(lambda, x)) / factorial(x);\n        cumulativeProbability += cells[x];\n        x++;\n    // when the cumulativeProbability is nearly 1, we've calculated\n    // the useful range of this distribution\n    } while (cumulativeProbability < 1 - epsilon);\n\n    return cells;\n}\n\nmodule.exports = poissonDistribution;\n",
    "'use strict';\n/* @flow */\n\nvar epsilon = require(10);\nvar inverseErrorFunction = require(17);\n\n/**\n * The [Probit](http://en.wikipedia.org/wiki/Probit)\n * is the inverse of cumulativeStdNormalProbability(),\n * and is also known as the normal quantile function.\n *\n * It returns the number of standard deviations from the mean\n * where the p'th quantile of values can be found in a normal distribution.\n * So, for example, probit(0.5 + 0.6827/2) ≈ 1 because 68.27% of values are\n * normally found within 1 standard deviation above or below the mean.\n *\n * @param {number} p\n * @returns {number} probit\n */\nfunction probit(p /*: number */)/*: number */ {\n    if (p === 0) {\n        p = epsilon;\n    } else if (p >= 1) {\n        p = 1 - epsilon;\n    }\n    return Math.sqrt(2) * inverseErrorFunction(2 * p - 1);\n}\n\nmodule.exports = probit;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [product](https://en.wikipedia.org/wiki/Product_(mathematics)) of an array\n * is the result of multiplying all numbers together, starting using one as the multiplicative identity.\n *\n * This runs on `O(n)`, linear time in respect to the array\n *\n * @param {Array<number>} x input\n * @return {number} product of all input numbers\n * @example\n * console.log(product([1, 2, 3, 4])); // 24\n */\nfunction product(x/*: Array<number> */)/*: number */ {\n    var value = 1;\n    for (var i = 0; i < x.length; i++) {\n        value *= x[i];\n    }\n    return value;\n}\n\nmodule.exports = product;\n",
    "'use strict';\n/* @flow */\n\nvar quantileSorted = require(35);\nvar numericSort = require(29);\n\n/**\n * The [quantile](https://en.wikipedia.org/wiki/Quantile):\n * this is a population quantile, since we assume to know the entire\n * dataset in this library. This is an implementation of the\n * [Quantiles of a Population](http://en.wikipedia.org/wiki/Quantile#Quantiles_of_a_population)\n * algorithm from wikipedia.\n *\n * Sample is a one-dimensional array of numbers,\n * and p is either a decimal number from 0 to 1 or an array of decimal\n * numbers from 0 to 1.\n * In terms of a k/q quantile, p = k/q - it's just dealing with fractions or dealing\n * with decimal values.\n * When p is an array, the result of the function is also an array containing the appropriate\n * quantiles in input order\n *\n * @param {Array<number>} sample a sample from the population\n * @param {number} p the desired quantile, as a number between 0 and 1\n * @returns {number} quantile\n * @example\n * var data = [3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20];\n * quantile(data, 1); //= max(data);\n * quantile(data, 0); //= min(data);\n * quantile(data, 0.5); //= 9\n */\nfunction quantile(sample /*: Array<number> */, p /*: Array<number> | number */) {\n    // Sort a copy of the array. We'll need a sorted array to index\n    // the values in sorted order.\n    var sorted = numericSort(sample);\n\n    if (Array.isArray(p)) {\n        // Initialize the result array\n        var results = [];\n        // For each requested quantile\n        for (var i = 0; i < p.length; i++) {\n            results[i] = quantileSorted(sorted, p[i]);\n        }\n        return results;\n    } else {\n        return quantileSorted(sorted, p);\n    }\n}\n\nmodule.exports = quantile;\n",
    "'use strict';\n/* @flow */\n\n/**\n * This is the internal implementation of quantiles: when you know\n * that the order is sorted, you don't need to re-sort it, and the computations\n * are faster.\n *\n * @param {Array<number>} sample input data\n * @param {number} p desired quantile: a number between 0 to 1, inclusive\n * @returns {number} quantile value\n * @example\n * var data = [3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20];\n * quantileSorted(data, 1); //= max(data);\n * quantileSorted(data, 0); //= min(data);\n * quantileSorted(data, 0.5); //= 9\n */\nfunction quantileSorted(sample /*: Array<number> */, p /*: number */)/*:number*/ {\n    var idx = sample.length * p;\n    if (p < 0 || p > 1) {\n        return NaN;\n    } else if (p === 1) {\n        // If p is 1, directly return the last element\n        return sample[sample.length - 1];\n    } else if (p === 0) {\n        // If p is 0, directly return the first element\n        return sample[0];\n    } else if (idx % 1 !== 0) {\n        // If p is not integer, return the next element in array\n        return sample[Math.ceil(idx) - 1];\n    } else if (sample.length % 2 === 0) {\n        // If the list has even-length, we'll take the average of this number\n        // and the next value, if there is one\n        return (sample[idx - 1] + sample[idx]) / 2;\n    } else {\n        // Finally, in the simple case of an integer value\n        // with an odd-length list, return the sample value at the index.\n        return sample[idx];\n    }\n}\n\nmodule.exports = quantileSorted;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [R Squared](http://en.wikipedia.org/wiki/Coefficient_of_determination)\n * value of data compared with a function `f`\n * is the sum of the squared differences between the prediction\n * and the actual value.\n *\n * @param {Array<Array<number>>} data input data: this should be doubly-nested\n * @param {Function} func function called on `[i][0]` values within the dataset\n * @returns {number} r-squared value\n * @example\n * var samples = [[0, 0], [1, 1]];\n * var regressionLine = linearRegressionLine(linearRegression(samples));\n * rSquared(samples, regressionLine); //= 1 this line is a perfect fit\n */\nfunction rSquared(data /*: Array<Array<number>> */, func /*: Function */) /*: number */ {\n    if (data.length < 2) { return 1; }\n\n    // Compute the average y value for the actual\n    // data set in order to compute the\n    // _total sum of squares_\n    var sum = 0, average;\n    for (var i = 0; i < data.length; i++) {\n        sum += data[i][1];\n    }\n    average = sum / data.length;\n\n    // Compute the total sum of squares - the\n    // squared difference between each point\n    // and the average of all points.\n    var sumOfSquares = 0;\n    for (var j = 0; j < data.length; j++) {\n        sumOfSquares += Math.pow(average - data[j][1], 2);\n    }\n\n    // Finally estimate the error: the squared\n    // difference between the estimate and the actual data\n    // value at each point.\n    var err = 0;\n    for (var k = 0; k < data.length; k++) {\n        err += Math.pow(data[k][1] - func(data[k][0]), 2);\n    }\n\n    // As the error grows larger, its ratio to the\n    // sum of squares increases and the r squared\n    // value grows lower.\n    return 1 - err / sumOfSquares;\n}\n\nmodule.exports = rSquared;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The Root Mean Square (RMS) is\n * a mean function used as a measure of the magnitude of a set\n * of numbers, regardless of their sign.\n * This is the square root of the mean of the squares of the\n * input numbers.\n * This runs on `O(n)`, linear time in respect to the array\n *\n * @param {Array<number>} x input\n * @returns {number} root mean square\n * @example\n * rootMeanSquare([-1, 1, -1, 1]); //= 1\n */\nfunction rootMeanSquare(x /*: Array<number> */)/*:number*/ {\n    if (x.length === 0) { return NaN; }\n\n    var sumOfSquares = 0;\n    for (var i = 0; i < x.length; i++) {\n        sumOfSquares += Math.pow(x[i], 2);\n    }\n\n    return Math.sqrt(sumOfSquares / x.length);\n}\n\nmodule.exports = rootMeanSquare;\n",
    "'use strict';\n/* @flow */\n\nvar shuffle = require(44);\n\n/**\n * Create a [simple random sample](http://en.wikipedia.org/wiki/Simple_random_sample)\n * from a given array of `n` elements.\n *\n * The sampled values will be in any order, not necessarily the order\n * they appear in the input.\n *\n * @param {Array} array input array. can contain any type\n * @param {number} n count of how many elements to take\n * @param {Function} [randomSource=Math.random] an optional source of entropy\n * instead of Math.random\n * @return {Array} subset of n elements in original array\n * @example\n * var values = [1, 2, 4, 5, 6, 7, 8, 9];\n * sample(values, 3); // returns 3 random values, like [2, 5, 8];\n */\nfunction sample/*:: <T> */(\n    array /*: Array<T> */,\n    n /*: number */,\n    randomSource /*: Function */) /*: Array<T> */ {\n    // shuffle the original array using a fisher-yates shuffle\n    var shuffled = shuffle(array, randomSource);\n\n    // and then return a subset of it - the first `n` elements.\n    return shuffled.slice(0, n);\n}\n\nmodule.exports = sample;\n",
    "'use strict';\n/* @flow */\n\nvar sampleCovariance = require(40);\nvar sampleStandardDeviation = require(42);\n\n/**\n * The [correlation](http://en.wikipedia.org/wiki/Correlation_and_dependence) is\n * a measure of how correlated two datasets are, between -1 and 1\n *\n * @param {Array<number>} x first input\n * @param {Array<number>} y second input\n * @returns {number} sample correlation\n * @example\n * var a = [1, 2, 3, 4, 5, 6];\n * var b = [2, 2, 3, 4, 5, 60];\n * sampleCorrelation(a, b); //= 0.691\n */\nfunction sampleCorrelation(x/*: Array<number> */, y/*: Array<number> */)/*:number*/ {\n    var cov = sampleCovariance(x, y),\n        xstd = sampleStandardDeviation(x),\n        ystd = sampleStandardDeviation(y);\n\n    return cov / xstd / ystd;\n}\n\nmodule.exports = sampleCorrelation;\n",
    "'use strict';\n/* @flow */\n\nvar mean = require(22);\n\n/**\n * [Sample covariance](https://en.wikipedia.org/wiki/Sample_mean_and_sampleCovariance) of two datasets:\n * how much do the two datasets move together?\n * x and y are two datasets, represented as arrays of numbers.\n *\n * @param {Array<number>} x first input\n * @param {Array<number>} y second input\n * @returns {number} sample covariance\n * @example\n * var x = [1, 2, 3, 4, 5, 6];\n * var y = [6, 5, 4, 3, 2, 1];\n * sampleCovariance(x, y); //= -3.5\n */\nfunction sampleCovariance(x /*:Array<number>*/, y /*:Array<number>*/)/*:number*/ {\n\n    // The two datasets must have the same length which must be more than 1\n    if (x.length <= 1 || x.length !== y.length) {\n        return NaN;\n    }\n\n    // determine the mean of each dataset so that we can judge each\n    // value of the dataset fairly as the difference from the mean. this\n    // way, if one dataset is [1, 2, 3] and [2, 3, 4], their covariance\n    // does not suffer because of the difference in absolute values\n    var xmean = mean(x),\n        ymean = mean(y),\n        sum = 0;\n\n    // for each pair of values, the covariance increases when their\n    // difference from the mean is associated - if both are well above\n    // or if both are well below\n    // the mean, the covariance increases significantly.\n    for (var i = 0; i < x.length; i++) {\n        sum += (x[i] - xmean) * (y[i] - ymean);\n    }\n\n    // this is Bessels' Correction: an adjustment made to sample statistics\n    // that allows for the reduced degree of freedom entailed in calculating\n    // values from samples rather than complete populations.\n    var besselsCorrection = x.length - 1;\n\n    // the covariance is weighted by the length of the datasets.\n    return sum / besselsCorrection;\n}\n\nmodule.exports = sampleCovariance;\n",
    "'use strict';\n/* @flow */\n\nvar sumNthPowerDeviations = require(50);\nvar sampleStandardDeviation = require(42);\n\n/**\n * [Skewness](http://en.wikipedia.org/wiki/Skewness) is\n * a measure of the extent to which a probability distribution of a\n * real-valued random variable \"leans\" to one side of the mean.\n * The skewness value can be positive or negative, or even undefined.\n *\n * Implementation is based on the adjusted Fisher-Pearson standardized\n * moment coefficient, which is the version found in Excel and several\n * statistical packages including Minitab, SAS and SPSS.\n *\n * @param {Array<number>} x input\n * @returns {number} sample skewness\n * @example\n * var data = [2, 4, 6, 3, 1];\n * sampleSkewness(data); //= 0.5901286564\n */\nfunction sampleSkewness(x /*: Array<number> */)/*:number*/ {\n    // The skewness of less than three arguments is null\n    var theSampleStandardDeviation = sampleStandardDeviation(x);\n\n    if (isNaN(theSampleStandardDeviation) || x.length < 3) {\n        return NaN;\n    }\n\n    var n = x.length,\n        cubedS = Math.pow(theSampleStandardDeviation, 3),\n        sumCubedDeviations = sumNthPowerDeviations(x, 3);\n\n    return n * sumCubedDeviations / ((n - 1) * (n - 2) * cubedS);\n}\n\nmodule.exports = sampleSkewness;\n",
    "'use strict';\n/* @flow */\n\nvar sampleVariance = require(43);\n\n/**\n * The [standard deviation](http://en.wikipedia.org/wiki/Standard_deviation)\n * is the square root of the variance.\n *\n * @param {Array<number>} x input array\n * @returns {number} sample standard deviation\n * @example\n * ss.sampleStandardDeviation([2, 4, 4, 4, 5, 5, 7, 9]);\n * //= 2.138\n */\nfunction sampleStandardDeviation(x/*:Array<number>*/)/*:number*/ {\n    // The standard deviation of no numbers is null\n    var sampleVarianceX = sampleVariance(x);\n    if (isNaN(sampleVarianceX)) { return NaN; }\n    return Math.sqrt(sampleVarianceX);\n}\n\nmodule.exports = sampleStandardDeviation;\n",
    "'use strict';\n/* @flow */\n\nvar sumNthPowerDeviations = require(50);\n\n/*\n * The [sample variance](https://en.wikipedia.org/wiki/Variance#Sample_variance)\n * is the sum of squared deviations from the mean. The sample variance\n * is distinguished from the variance by the usage of [Bessel's Correction](https://en.wikipedia.org/wiki/Bessel's_correction):\n * instead of dividing the sum of squared deviations by the length of the input,\n * it is divided by the length minus one. This corrects the bias in estimating\n * a value from a set that you don't know if full.\n *\n * References:\n * * [Wolfram MathWorld on Sample Variance](http://mathworld.wolfram.com/SampleVariance.html)\n *\n * @param {Array<number>} x input array\n * @return {number} sample variance\n * @example\n * sampleVariance([1, 2, 3, 4, 5]); //= 2.5\n */\nfunction sampleVariance(x /*: Array<number> */)/*:number*/ {\n    // The variance of no numbers is null\n    if (x.length <= 1) { return NaN; }\n\n    var sumSquaredDeviationsValue = sumNthPowerDeviations(x, 2);\n\n    // this is Bessels' Correction: an adjustment made to sample statistics\n    // that allows for the reduced degree of freedom entailed in calculating\n    // values from samples rather than complete populations.\n    var besselsCorrection = x.length - 1;\n\n    // Find the mean value of that list\n    return sumSquaredDeviationsValue / besselsCorrection;\n}\n\nmodule.exports = sampleVariance;\n",
    "'use strict';\n/* @flow */\n\nvar shuffleInPlace = require(45);\n\n/*\n * A [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle)\n * is a fast way to create a random permutation of a finite set. This is\n * a function around `shuffle_in_place` that adds the guarantee that\n * it will not modify its input.\n *\n * @param {Array} sample an array of any kind of element\n * @param {Function} [randomSource=Math.random] an optional entropy source\n * @return {Array} shuffled version of input\n * @example\n * var shuffled = shuffle([1, 2, 3, 4]);\n * shuffled; // = [2, 3, 1, 4] or any other random permutation\n */\nfunction shuffle/*::<T>*/(sample/*:Array<T>*/, randomSource/*:Function*/) {\n    // slice the original array so that it is not modified\n    sample = sample.slice();\n\n    // and then shuffle that shallow-copied array, in place\n    return shuffleInPlace(sample.slice(), randomSource);\n}\n\nmodule.exports = shuffle;\n",
    "'use strict';\n/* @flow */\n\n/*\n * A [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle)\n * in-place - which means that it **will change the order of the original\n * array by reference**.\n *\n * This is an algorithm that generates a random [permutation](https://en.wikipedia.org/wiki/Permutation)\n * of a set.\n *\n * @param {Array} sample input array\n * @param {Function} [randomSource=Math.random] an optional source of entropy\n * @returns {Array} sample\n * @example\n * var sample = [1, 2, 3, 4];\n * shuffleInPlace(sample);\n * // sample is shuffled to a value like [2, 1, 4, 3]\n */\nfunction shuffleInPlace(sample/*:Array<any>*/, randomSource/*:Function*/)/*:Array<any>*/ {\n\n\n    // a custom random number source can be provided if you want to use\n    // a fixed seed or another random number generator, like\n    // [random-js](https://www.npmjs.org/package/random-js)\n    randomSource = randomSource || Math.random;\n\n    // store the current length of the sample to determine\n    // when no elements remain to shuffle.\n    var length = sample.length;\n\n    // temporary is used to hold an item when it is being\n    // swapped between indices.\n    var temporary;\n\n    // The index to swap at each stage.\n    var index;\n\n    // While there are still items to shuffle\n    while (length > 0) {\n        // chose a random index within the subset of the array\n        // that is not yet shuffled\n        index = Math.floor(randomSource() * length--);\n\n        // store the value that we'll move temporarily\n        temporary = sample[length];\n\n        // swap the value at `sample[length]` with `sample[index]`\n        sample[length] = sample[index];\n        sample[index] = temporary;\n    }\n\n    return sample;\n}\n\nmodule.exports = shuffleInPlace;\n",
    "'use strict';\n/* @flow */\n\n/**\n * For a sorted input, counting the number of unique values\n * is possible in constant time and constant memory. This is\n * a simple implementation of the algorithm.\n *\n * Values are compared with `===`, so objects and non-primitive objects\n * are not handled in any special way.\n *\n * @param {Array} input an array of primitive values.\n * @returns {number} count of unique values\n * @example\n * sortedUniqueCount([1, 2, 3]); // 3\n * sortedUniqueCount([1, 1, 1]); // 1\n */\nfunction sortedUniqueCount(input/*: Array<any>*/)/*: number */ {\n    var uniqueValueCount = 0,\n        lastSeenValue;\n    for (var i = 0; i < input.length; i++) {\n        if (i === 0 || input[i] !== lastSeenValue) {\n            lastSeenValue = input[i];\n            uniqueValueCount++;\n        }\n    }\n    return uniqueValueCount;\n}\n\nmodule.exports = sortedUniqueCount;\n",
    "'use strict';\n/* @flow */\n\nvar variance = require(53);\n\n/**\n * The [standard deviation](http://en.wikipedia.org/wiki/Standard_deviation)\n * is the square root of the variance. It's useful for measuring the amount\n * of variation or dispersion in a set of values.\n *\n * Standard deviation is only appropriate for full-population knowledge: for\n * samples of a population, {@link sampleStandardDeviation} is\n * more appropriate.\n *\n * @param {Array<number>} x input\n * @returns {number} standard deviation\n * @example\n * var scores = [2, 4, 4, 4, 5, 5, 7, 9];\n * variance(scores); //= 4\n * standardDeviation(scores); //= 2\n */\nfunction standardDeviation(x /*: Array<number> */)/*:number*/ {\n    // The standard deviation of no numbers is null\n    var v = variance(x);\n    if (isNaN(v)) { return 0; }\n    return Math.sqrt(v);\n}\n\nmodule.exports = standardDeviation;\n",
    "'use strict';\n/* @flow */\n\nvar SQRT_2PI = Math.sqrt(2 * Math.PI);\n\nfunction cumulativeDistribution(z) {\n    var sum = z,\n        tmp = z;\n\n    // 15 iterations are enough for 4-digit precision\n    for (var i = 1; i < 15; i++) {\n        tmp *= z * z / (2 * i + 1);\n        sum += tmp;\n    }\n    return Math.round((0.5 + (sum / SQRT_2PI) * Math.exp(-z * z / 2)) * 1e4) / 1e4;\n}\n\n/**\n * A standard normal table, also called the unit normal table or Z table,\n * is a mathematical table for the values of Φ (phi), which are the values of\n * the cumulative distribution function of the normal distribution.\n * It is used to find the probability that a statistic is observed below,\n * above, or between values on the standard normal distribution, and by\n * extension, any normal distribution.\n *\n * The probabilities are calculated using the\n * [Cumulative distribution function](https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function).\n * The table used is the cumulative, and not cumulative from 0 to mean\n * (even though the latter has 5 digits precision, instead of 4).\n */\nvar standardNormalTable/*: Array<number> */ = [];\n\nfor (var z = 0; z <= 3.09; z += 0.01) {\n    standardNormalTable.push(cumulativeDistribution(z));\n}\n\nmodule.exports = standardNormalTable;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [sum](https://en.wikipedia.org/wiki/Summation) of an array\n * is the result of adding all numbers together, starting from zero.\n *\n * This runs on `O(n)`, linear time in respect to the array\n *\n * @param {Array<number>} x input\n * @return {number} sum of all input numbers\n * @example\n * console.log(sum([1, 2, 3])); // 6\n */\nfunction sum(x/*: Array<number> */)/*: number */ {\n    var value = 0;\n    for (var i = 0; i < x.length; i++) {\n        value += x[i];\n    }\n    return value;\n}\n\nmodule.exports = sum;\n",
    "'use strict';\n/* @flow */\n\nvar mean = require(22);\n\n/**\n * The sum of deviations to the Nth power.\n * When n=2 it's the sum of squared deviations.\n * When n=3 it's the sum of cubed deviations.\n *\n * @param {Array<number>} x\n * @param {number} n power\n * @returns {number} sum of nth power deviations\n * @example\n * var input = [1, 2, 3];\n * // since the variance of a set is the mean squared\n * // deviations, we can calculate that with sumNthPowerDeviations:\n * var variance = sumNthPowerDeviations(input) / input.length;\n */\nfunction sumNthPowerDeviations(x/*: Array<number> */, n/*: number */)/*:number*/ {\n    var meanValue = mean(x),\n        sum = 0;\n\n    for (var i = 0; i < x.length; i++) {\n        sum += Math.pow(x[i] - meanValue, n);\n    }\n\n    return sum;\n}\n\nmodule.exports = sumNthPowerDeviations;\n",
    "'use strict';\n/* @flow */\n\nvar standardDeviation = require(47);\nvar mean = require(22);\n\n/**\n * This is to compute [a one-sample t-test](https://en.wikipedia.org/wiki/Student%27s_t-test#One-sample_t-test), comparing the mean\n * of a sample to a known value, x.\n *\n * in this case, we're trying to determine whether the\n * population mean is equal to the value that we know, which is `x`\n * here. usually the results here are used to look up a\n * [p-value](http://en.wikipedia.org/wiki/P-value), which, for\n * a certain level of significance, will let you determine that the\n * null hypothesis can or cannot be rejected.\n *\n * @param {Array<number>} sample an array of numbers as input\n * @param {number} x expected vale of the population mean\n * @returns {number} value\n * @example\n * tTest([1, 2, 3, 4, 5, 6], 3.385); //= 0.16494154\n */\nfunction tTest(sample/*: Array<number> */, x/*: number */)/*:number*/ {\n    // The mean of the sample\n    var sampleMean = mean(sample);\n\n    // The standard deviation of the sample\n    var sd = standardDeviation(sample);\n\n    // Square root the length of the sample\n    var rootN = Math.sqrt(sample.length);\n\n    // returning the t value\n    return (sampleMean - x) / (sd / rootN);\n}\n\nmodule.exports = tTest;\n",
    "'use strict';\n/* @flow */\n\nvar mean = require(22);\nvar sampleVariance = require(43);\n\n/**\n * This is to compute [two sample t-test](http://en.wikipedia.org/wiki/Student's_t-test).\n * Tests whether \"mean(X)-mean(Y) = difference\", (\n * in the most common case, we often have `difference == 0` to test if two samples\n * are likely to be taken from populations with the same mean value) with\n * no prior knowledge on standard deviations of both samples\n * other than the fact that they have the same standard deviation.\n *\n * Usually the results here are used to look up a\n * [p-value](http://en.wikipedia.org/wiki/P-value), which, for\n * a certain level of significance, will let you determine that the\n * null hypothesis can or cannot be rejected.\n *\n * `diff` can be omitted if it equals 0.\n *\n * [This is used to confirm or deny](http://www.monarchlab.org/Lab/Research/Stats/2SampleT.aspx)\n * a null hypothesis that the two populations that have been sampled into\n * `sampleX` and `sampleY` are equal to each other.\n *\n * @param {Array<number>} sampleX a sample as an array of numbers\n * @param {Array<number>} sampleY a sample as an array of numbers\n * @param {number} [difference=0]\n * @returns {number} test result\n * @example\n * ss.tTestTwoSample([1, 2, 3, 4], [3, 4, 5, 6], 0); //= -2.1908902300206643\n */\nfunction tTestTwoSample(\n    sampleX/*: Array<number> */,\n    sampleY/*: Array<number> */,\n    difference/*: number */) {\n    var n = sampleX.length,\n        m = sampleY.length;\n\n    // If either sample doesn't actually have any values, we can't\n    // compute this at all, so we return `null`.\n    if (!n || !m) { return null; }\n\n    // default difference (mu) is zero\n    if (!difference) {\n        difference = 0;\n    }\n\n    var meanX = mean(sampleX),\n        meanY = mean(sampleY),\n        sampleVarianceX = sampleVariance(sampleX),\n        sampleVarianceY = sampleVariance(sampleY);\n\n    if (typeof meanX === 'number' &&\n        typeof meanY === 'number' &&\n        typeof sampleVarianceX === 'number' &&\n        typeof sampleVarianceY === 'number') {\n        var weightedVariance = ((n - 1) * sampleVarianceX +\n            (m - 1) * sampleVarianceY) / (n + m - 2);\n\n        return (meanX - meanY - difference) /\n            Math.sqrt(weightedVariance * (1 / n + 1 / m));\n    }\n}\n\nmodule.exports = tTestTwoSample;\n",
    "'use strict';\n/* @flow */\n\nvar sumNthPowerDeviations = require(50);\n\n/**\n * The [variance](http://en.wikipedia.org/wiki/Variance)\n * is the sum of squared deviations from the mean.\n *\n * This is an implementation of variance, not sample variance:\n * see the `sampleVariance` method if you want a sample measure.\n *\n * @param {Array<number>} x a population\n * @returns {number} variance: a value greater than or equal to zero.\n * zero indicates that all values are identical.\n * @example\n * ss.variance([1, 2, 3, 4, 5, 6]); //= 2.917\n */\nfunction variance(x/*: Array<number> */)/*:number*/ {\n    // The variance of no numbers is null\n    if (x.length === 0) { return NaN; }\n\n    // Find the mean of squared deviations between the\n    // mean value and each value.\n    return sumNthPowerDeviations(x, 2) / x.length;\n}\n\nmodule.exports = variance;\n",
    "'use strict';\n/* @flow */\n\n/**\n * The [Z-Score, or Standard Score](http://en.wikipedia.org/wiki/Standard_score).\n *\n * The standard score is the number of standard deviations an observation\n * or datum is above or below the mean. Thus, a positive standard score\n * represents a datum above the mean, while a negative standard score\n * represents a datum below the mean. It is a dimensionless quantity\n * obtained by subtracting the population mean from an individual raw\n * score and then dividing the difference by the population standard\n * deviation.\n *\n * The z-score is only defined if one knows the population parameters;\n * if one only has a sample set, then the analogous computation with\n * sample mean and sample standard deviation yields the\n * Student's t-statistic.\n *\n * @param {number} x\n * @param {number} mean\n * @param {number} standardDeviation\n * @return {number} z score\n * @example\n * ss.zScore(78, 80, 5); //= -0.4\n */\nfunction zScore(x/*:number*/, mean/*:number*/, standardDeviation/*:number*/)/*:number*/ {\n    return (x - mean) / standardDeviation;\n}\n\nmodule.exports = zScore;\n"
  ]
}